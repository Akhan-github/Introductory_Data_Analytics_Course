{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"handling_missing_value.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1tlpM-sqKa2plNeOaKiuUsaNVQbTTKyBR","authorship_tag":"ABX9TyPLQg2ukHM2ML9czJYH9rUZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"U6ejnf5qigbu"},"source":["<a href=\"https://colab.research.google.com/drive/1tlpM-sqKa2plNeOaKiuUsaNVQbTTKyBR?usp=sharing\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"markdown","metadata":{"id":"d3KhLoZzipY6"},"source":["This tutorial needs data so if you are working on colab follow the below data setup instruction"]},{"cell_type":"markdown","metadata":{"id":"DJj80mY6eXle"},"source":["# Data Setup Instructions"]},{"cell_type":"markdown","metadata":{"id":"u8GveGfqfaKR"},"source":["These are the instructions for mounting the data from google drive to colab and accessing it in the colab."]},{"cell_type":"markdown","metadata":{"id":"0alFBPisfilw"},"source":["STEP 1 - After opening the tutorial in  your colab, go to folder button and click on mount google drive"]},{"cell_type":"markdown","metadata":{"id":"NmurPLOTfrJv"},"source":["STEP 2 - drive folder will be mounted in the current directory of /content, you can access it as below "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"NtQZjZNrf-4a","executionInfo":{"status":"ok","timestamp":1630081882881,"user_tz":-330,"elapsed":524,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}},"outputId":"31da032b-f0d0-420b-e0c9-9d121601faac"},"source":["# print current directory\n","%pwd"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOzwj-bggCYC","executionInfo":{"status":"ok","timestamp":1630081885037,"user_tz":-330,"elapsed":10,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}},"outputId":"8e035959-9399-4996-d51d-bac260c5f08c"},"source":["%ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v_ls4HDRgD4S"},"source":["STEP 3 - Find your data folder where you saved the data and sym link it to /content folder so as to simplify data access"]},{"cell_type":"markdown","metadata":{"id":"Aa_Pc0gKgWIg"},"source":["In the current case the Data folder is located at this path in google drive (Use your own data path in your case)\n","\n","/content/drive/Othercomputers/My MacBook Pro/Data/\n","\n","We can sym link it to /content folder using the following command"]},{"cell_type":"code","metadata":{"id":"Y3kLUPXtgrrJ","executionInfo":{"status":"ok","timestamp":1630081892591,"user_tz":-330,"elapsed":565,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}}},"source":["# sym linked the original data folder to new location at /content\n","!ln -s \"/content/drive/Othercomputers/My MacBook Pro/Data\" \"/content\""],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOccFPN8gu6q"},"source":["Now we can access the data from this folder by simply giving the file path name after /Data"]},{"cell_type":"markdown","metadata":{"id":"zUlUnMfSi9uF"},"source":["# Importing pandas library and data loading"]},{"cell_type":"code","metadata":{"id":"oN26v6EetuE0","executionInfo":{"status":"ok","timestamp":1630081915710,"user_tz":-330,"elapsed":594,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}}},"source":["import pandas as pd"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6dsiluoXtvuN"},"source":["In the last lesson we have saved the cleaned dataframe at the end in the file \n","\n","'movies_cleaned_lesson2.csv'.\n","\n","You can read this file in the below way (the path is taken from the previous lesson)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"id":"WGjH1c7St-Q4","executionInfo":{"status":"ok","timestamp":1630081920611,"user_tz":-330,"elapsed":1932,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}},"outputId":"3c1b1ff7-fbd3-4109-8834-19321c85d89f"},"source":["# if you are working with this tutorial on local machine use the file path where the data is saved in your computer\n","movies = pd.read_csv(\"Data/IMDB_rotten_tomato_dataset/IMDB/cleaned_files/movies_cleaned_lesson2.csv\")\n","# We can use .head command to quickly observe the first 5 rows of the dataset\n","movies.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>imdb_title_id</th>\n","      <th>original_title</th>\n","      <th>year</th>\n","      <th>date_published</th>\n","      <th>genre</th>\n","      <th>duration</th>\n","      <th>country</th>\n","      <th>language</th>\n","      <th>imdb_score</th>\n","      <th>votes</th>\n","      <th>budget</th>\n","      <th>usa_gross_income</th>\n","      <th>worldwide_gross_income</th>\n","      <th>metascore</th>\n","      <th>movie_age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tt0000009</td>\n","      <td>Miss Jerry</td>\n","      <td>1894</td>\n","      <td>1894-10-09</td>\n","      <td>Romance</td>\n","      <td>45</td>\n","      <td>USA</td>\n","      <td>None</td>\n","      <td>5.9</td>\n","      <td>154</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>127</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>tt0000574</td>\n","      <td>The Story of the Kelly Gang</td>\n","      <td>1906</td>\n","      <td>1906-12-26</td>\n","      <td>Biography, Crime, Drama</td>\n","      <td>70</td>\n","      <td>Australia</td>\n","      <td>None</td>\n","      <td>6.1</td>\n","      <td>589</td>\n","      <td>$ 2250</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>115</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tt0001892</td>\n","      <td>Den sorte drøm</td>\n","      <td>1911</td>\n","      <td>1911-08-19</td>\n","      <td>Drama</td>\n","      <td>53</td>\n","      <td>Germany, Denmark</td>\n","      <td>NaN</td>\n","      <td>5.8</td>\n","      <td>188</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>110</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>tt0002101</td>\n","      <td>Cleopatra</td>\n","      <td>1912</td>\n","      <td>1912-11-13</td>\n","      <td>Drama, History</td>\n","      <td>100</td>\n","      <td>USA</td>\n","      <td>English</td>\n","      <td>5.2</td>\n","      <td>446</td>\n","      <td>$ 45000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>109</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>tt0002130</td>\n","      <td>L'Inferno</td>\n","      <td>1911</td>\n","      <td>1911-03-06</td>\n","      <td>Adventure, Drama, Fantasy</td>\n","      <td>68</td>\n","      <td>Italy</td>\n","      <td>Italian</td>\n","      <td>7.0</td>\n","      <td>2237</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>110</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  imdb_title_id               original_title  ...  metascore movie_age\n","0     tt0000009                   Miss Jerry  ...        NaN       127\n","1     tt0000574  The Story of the Kelly Gang  ...        NaN       115\n","2     tt0001892               Den sorte drøm  ...        NaN       110\n","3     tt0002101                    Cleopatra  ...        NaN       109\n","4     tt0002130                    L'Inferno  ...        NaN       110\n","\n","[5 rows x 15 columns]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"qaICA32EULrB"},"source":["### Handling missing values"]},{"cell_type":"markdown","metadata":{"id":"yoLB7Gy-ULrB"},"source":["If you will observe the worldwide_gross_income column, there are many missing values (missing values are denoted by NaN)"]},{"cell_type":"code","metadata":{"id":"g7Uf9W-YULrB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630081968440,"user_tz":-330,"elapsed":456,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}},"outputId":"490b477b-b6ca-4501-8051-d7ce2dc0f841"},"source":["movies['worldwide_gross_income']"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0              NaN\n","1              NaN\n","2              NaN\n","3              NaN\n","4              NaN\n","           ...    \n","85849    $ 3507171\n","85850    $ 7299062\n","85851          NaN\n","85852       $ 2833\n","85853      $ 59794\n","Name: worldwide_gross_income, Length: 85854, dtype: object"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"0F1up3j8ULrB"},"source":["One of the basic data cleaning step that can be done on any dataset is to find missing values in the data. If this data can not be filled up, then it should be removed. \n","\n","In our present case,we will create a separate dataset where we do not have any missing value in worldwide_gross_income column. This will help in working with income data of movies separately.\n","\n","We will be using .copy() command at the end of this command because it will create a completely new dataframe in this case rather than just a reference view of the dataframe. \n","\n","This will help us tackle 'SettingswithCopy' warning which may happen when we start working on this new dataframe later on. (This is a very frequent kind of warning in pandas library, we will learn more about it during the bigger course of OneLearn GetHired Program)"]},{"cell_type":"code","metadata":{"id":"A_rHsfimULrB","executionInfo":{"status":"ok","timestamp":1630081973298,"user_tz":-330,"elapsed":452,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}}},"source":["#.notnull() is the function used to filter movies which has some gross_income mentioned in data\n","movies_cleaned_gross_income = movies.loc[movies['worldwide_gross_income'].notnull()].copy()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bq_lcx8NULrB","colab":{"base_uri":"https://localhost:8080/","height":672},"executionInfo":{"status":"ok","timestamp":1630081975755,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}},"outputId":"33a50d77-a92f-49ee-cc71-05625a9cbb51"},"source":["movies_cleaned_gross_income"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>imdb_title_id</th>\n","      <th>original_title</th>\n","      <th>year</th>\n","      <th>date_published</th>\n","      <th>genre</th>\n","      <th>duration</th>\n","      <th>country</th>\n","      <th>language</th>\n","      <th>imdb_score</th>\n","      <th>votes</th>\n","      <th>budget</th>\n","      <th>usa_gross_income</th>\n","      <th>worldwide_gross_income</th>\n","      <th>metascore</th>\n","      <th>movie_age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>79</th>\n","      <td>tt0007183</td>\n","      <td>Pikovaya dama</td>\n","      <td>1916</td>\n","      <td>1916-04-01</td>\n","      <td>Drama, Fantasy, Horror</td>\n","      <td>63</td>\n","      <td>Russia</td>\n","      <td>Russian</td>\n","      <td>7.0</td>\n","      <td>610</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>$ 144968</td>\n","      <td>NaN</td>\n","      <td>105</td>\n","    </tr>\n","    <tr>\n","      <th>165</th>\n","      <td>tt0010323</td>\n","      <td>Das Cabinet des Dr. Caligari</td>\n","      <td>1920</td>\n","      <td>1920-02-27</td>\n","      <td>Fantasy, Horror, Mystery</td>\n","      <td>76</td>\n","      <td>Germany</td>\n","      <td>German</td>\n","      <td>8.1</td>\n","      <td>55601</td>\n","      <td>$ 18000</td>\n","      <td>$ 8811</td>\n","      <td>$ 8811</td>\n","      <td>NaN</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>210</th>\n","      <td>tt0011440</td>\n","      <td>Markens grøde</td>\n","      <td>1921</td>\n","      <td>1921-12-02</td>\n","      <td>Drama</td>\n","      <td>107</td>\n","      <td>Norway</td>\n","      <td>NaN</td>\n","      <td>6.6</td>\n","      <td>195</td>\n","      <td>NOK 250000</td>\n","      <td>NaN</td>\n","      <td>$ 4272</td>\n","      <td>NaN</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>222</th>\n","      <td>tt0011741</td>\n","      <td>Suds</td>\n","      <td>1920</td>\n","      <td>1920-01-27</td>\n","      <td>Comedy, Drama, Romance</td>\n","      <td>75</td>\n","      <td>USA</td>\n","      <td>English</td>\n","      <td>6.3</td>\n","      <td>210</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>$ 772155</td>\n","      <td>NaN</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>tt0012190</td>\n","      <td>The Four Horsemen of the Apocalypse</td>\n","      <td>1921</td>\n","      <td>1923-04-16</td>\n","      <td>Drama, Romance, War</td>\n","      <td>150</td>\n","      <td>USA</td>\n","      <td>None</td>\n","      <td>7.2</td>\n","      <td>3058</td>\n","      <td>$ 800000</td>\n","      <td>$ 9183673</td>\n","      <td>$ 9183673</td>\n","      <td>NaN</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>85846</th>\n","      <td>tt9905412</td>\n","      <td>Ottam</td>\n","      <td>2019</td>\n","      <td>2019-03-08</td>\n","      <td>Drama</td>\n","      <td>120</td>\n","      <td>India</td>\n","      <td>Malayalam</td>\n","      <td>7.4</td>\n","      <td>494</td>\n","      <td>INR 4000000</td>\n","      <td>NaN</td>\n","      <td>$ 4791</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>85849</th>\n","      <td>tt9908390</td>\n","      <td>Le lion</td>\n","      <td>2020</td>\n","      <td>2020-01-29</td>\n","      <td>Comedy</td>\n","      <td>95</td>\n","      <td>France, Belgium</td>\n","      <td>French</td>\n","      <td>5.3</td>\n","      <td>398</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>$ 3507171</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>85850</th>\n","      <td>tt9911196</td>\n","      <td>De Beentjes van Sint-Hildegard</td>\n","      <td>2020</td>\n","      <td>2020-02-13</td>\n","      <td>Comedy, Drama</td>\n","      <td>103</td>\n","      <td>Netherlands</td>\n","      <td>German, Dutch</td>\n","      <td>7.7</td>\n","      <td>724</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>$ 7299062</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>85852</th>\n","      <td>tt9914286</td>\n","      <td>Sokagin Çocuklari</td>\n","      <td>2019</td>\n","      <td>2019-03-15</td>\n","      <td>Drama, Family</td>\n","      <td>98</td>\n","      <td>Turkey</td>\n","      <td>Turkish</td>\n","      <td>6.4</td>\n","      <td>194</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>$ 2833</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>85853</th>\n","      <td>tt9914942</td>\n","      <td>La vida sense la Sara Amat</td>\n","      <td>2019</td>\n","      <td>2020-02-05</td>\n","      <td>Drama</td>\n","      <td>74</td>\n","      <td>Spain</td>\n","      <td>Catalan</td>\n","      <td>6.7</td>\n","      <td>102</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>$ 59794</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31016 rows × 15 columns</p>\n","</div>"],"text/plain":["      imdb_title_id                       original_title  ...  metascore movie_age\n","79        tt0007183                        Pikovaya dama  ...        NaN       105\n","165       tt0010323         Das Cabinet des Dr. Caligari  ...        NaN       101\n","210       tt0011440                        Markens grøde  ...        NaN       100\n","222       tt0011741                                 Suds  ...        NaN       101\n","245       tt0012190  The Four Horsemen of the Apocalypse  ...        NaN       100\n","...             ...                                  ...  ...        ...       ...\n","85846     tt9905412                                Ottam  ...        NaN         2\n","85849     tt9908390                              Le lion  ...        NaN         1\n","85850     tt9911196       De Beentjes van Sint-Hildegard  ...        NaN         1\n","85852     tt9914286                    Sokagin Çocuklari  ...        NaN         2\n","85853     tt9914942           La vida sense la Sara Amat  ...        NaN         2\n","\n","[31016 rows x 15 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"fw3iaPXsjXch"},"source":["You can observe the number of rows in this data frame is 31016 which is quite less than the original numnber of rows in initial dataframe. But since in the bigger project we have to analyse earning potential of movies so we will have to remove missing values of worldwide_gross_income."]},{"cell_type":"markdown","metadata":{"id":"Jp6OO-mSMJ2N"},"source":["# Saving the cleaned data"]},{"cell_type":"markdown","metadata":{"id":"doOY6aVYJki8"},"source":["In this lesson we have not modified the initial dataframe movies, so we will not save it. But we have created a new dataframe 'movies_cleaned_gross_income'\n","\n","We will save the dataframe 'movies_cleaned_gross_income' in a new file called \n","\n","'movies_cleaned_lesson3.csv'\n","\n","in the folder cleaned_files.\n","\n","Final path of the saved file would be - 'Data/IMDB_rotten_tomato_dataset/IMDB/cleaned_files/movies_cleaned_lesson3.csv'"]},{"cell_type":"code","metadata":{"id":"fMnTg9brKLQ8","executionInfo":{"status":"ok","timestamp":1630083504607,"user_tz":-330,"elapsed":487,"user":{"displayName":"Arunesh Nandan","photoUrl":"","userId":"14301514947960066372"}}},"source":["# don't forget to put index = false while saving the data frame in a csv file\n","movies_cleaned_gross_income.to_csv('Data/IMDB_rotten_tomato_dataset/IMDB/cleaned_files/movies_cleaned_lesson3.csv', index = False)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jUZkXQEyKYzL"},"source":["We will use this file in the next lesson of Data Cleaning."]}]}